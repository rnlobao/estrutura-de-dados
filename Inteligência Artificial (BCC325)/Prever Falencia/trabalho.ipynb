{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "import operator\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjuntoTreinamento = pd.read_csv(\"conjunto_dados\\\\falencia-treinamento.csv\", delimiter=';')\n",
    "x_test = pd.read_csv(\"conjunto_dados\\\\falencia-teste.csv\", delimiter=';')\n",
    "\n",
    "conjuntoTreinamento.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "\n",
    "x_train = conjuntoTreinamento.drop(\"Resultado\", axis=1)\n",
    "y_train = conjuntoTreinamento[\"Resultado\"]\n",
    "\n",
    "x_test.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResultadosLogisticRegression(solver, penalty, tipoKfold, scoring, n_splits, x_train, y_train):\n",
    "    if(penalty == None):\n",
    "        print(\">> Modelo : Logistic Regression \" + \"; Solver : \" + solver + \" ; KFold : \" + tipoKfold + \" ; Penalidade : None ; Scoring : \" + scoring + \" ; Splits : \" + str(n_splits))\n",
    "    else:\n",
    "        print(\">> Modelo : Logistic Regression \" + \"; Solver : \" + solver + \" ; KFold : \" + tipoKfold + \" ; Penalidade : \" + penalty + \" ; Scoring : \" + scoring + \" ; Splits : \" + str(n_splits))\n",
    "\n",
    "\n",
    "    modelLogistic = LogisticRegression(solver=solver, penalty=penalty)\n",
    "    modelLogistic.fit(x_train, y_train)\n",
    "    y_pred = modelLogistic.predict(x_test)\n",
    "    \n",
    "    if (tipoKfold == 'KFold'):\n",
    "        cv = KFold(n_splits=n_splits, shuffle=True)\n",
    "    elif (tipoKfold == 'StratifiedKFold'):\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    vec = []\n",
    "    for i in range (10):\n",
    "        scoresModel = cross_val_score(modelLogistic, x_train, y_train, cv=cv, scoring=scoring)\n",
    "        vec.append(scoresModel)\n",
    "        # print(scoresModel)\n",
    "    \n",
    "    result = np.mean(vec, axis=0)\n",
    "    \n",
    "    return np.mean(result), np.std(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegressionAllCombinations():\n",
    "    solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "    penalties = ['l1', 'l2', None] # elasticnet not working\n",
    "    kfolds = [\"KFold\", \"StratifiedKFold\"]\n",
    "    splits = [10, 20]\n",
    "\n",
    "    #    - 'lbfgs'           -   ['l2', None]\n",
    "    #    - 'liblinear'       -   ['l1', 'l2']\n",
    "    #    - 'newton-cg'       -   ['l2', None]\n",
    "    #    - 'newton-cholesky' -   ['l2', None]\n",
    "    #    - 'sag'             -   ['l2', None]\n",
    "    #    - 'saga'            -   ['elasticnet', 'l1', 'l2', None]\n",
    "\n",
    "    logisticRegressionResults = []\n",
    "    for solver in solvers:\n",
    "        for penalty in penalties:\n",
    "            if (solver == 'lbfgs' and penalty != 'l2' and penalty != None):\n",
    "            \n",
    "                continue\n",
    "            if(solver == 'liblinear' and penalty != 'l1' and penalty != 'l2'):\n",
    "                continue\n",
    "            if(solver == 'newton-cg' or solver == 'newton-cholesky' or solver == 'sag' and penalty != 'l2' and penalty != None):\n",
    "                continue\n",
    "            for kf in kfolds:\n",
    "                for split in splits:\n",
    "                    logisticRegressionResults.append({\"solver\": solver, \"penalty\": penalty, \"kfold\": kf, \"splits\": split, \"result\": printResultadosLogisticRegression(solver, penalty, kf, \"f1\", split, x_train, y_train)})\n",
    "    return logisticRegressionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    r = logisticRegressionAllCombinations()\n",
    "    r.sort(key=operator.itemgetter(\"result\"), reverse=True)\n",
    "    with open(\"resultados/logisticRegression/logisticRegression\" + str(i+1) + \".txt\", \"w\") as file:\n",
    "        pprint.pprint(r, stream=file, sort_dicts=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore de Decisão (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResultadosDecisionTree(criterion, splitter, max_depth, tipoKfold, scoring, n_splits, x_train, y_train):\n",
    "    print(\">> Modelo : Decision Tree \" +  \"; Criterion : \" + criterion + \" ; Splitter : \" + splitter + \" ; Max_depth : \" + str(max_depth) + \" ; KFold : \" + tipoKfold + \" ; Scoring : \" + scoring + \" ; Splits : \" + str(n_splits))\n",
    "\n",
    "    modelDecisionTree = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth)\n",
    "    modelDecisionTree.fit(x_train, y_train)\n",
    "    y_pred = modelDecisionTree.predict(x_test)\n",
    "\n",
    "    if (tipoKfold == \"KFold\"):\n",
    "        cv = KFold(n_splits=n_splits, shuffle=True)\n",
    "    elif (tipoKfold == \"StratifiedKFold\"):\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    vec = []\n",
    "    for i in range (10):\n",
    "        scoresModel = cross_val_score(modelDecisionTree, x_train, y_train, cv=cv, scoring=scoring)\n",
    "        vec.append(scoresModel)\n",
    "        # print(scoresModel)\n",
    "    \n",
    "    result = np.mean(vec, axis=0)\n",
    "    \n",
    "    return np.mean(result), np.std(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTreeAllCombinations():\n",
    "    criterion = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "    splitter = [\"best\", \"random\"]\n",
    "    max_depth = [5, 10]\n",
    "    kfold = [\"KFold\", \"StratifiedKFold\"]\n",
    "    n_splits = [10, 20]\n",
    "\n",
    "    decisionTreeResults = []\n",
    "    for crit in criterion:\n",
    "        for split in splitter:\n",
    "            for depth in max_depth:\n",
    "                for kf in kfold:\n",
    "                    for nsplit in n_splits:\n",
    "                        decisionTreeResults.append({\"criterion\": crit, \"splitter\": split, \"kfold\": kf, \"max_depth\": depth, \"splits\" : nsplit, \"result\": printResultadosDecisionTree(crit, split, depth, kf, \"f1\", nsplit, x_train, y_train)})\n",
    "\n",
    "    return decisionTreeResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    r = decisionTreeAllCombinations()\n",
    "    r.sort(key=operator.itemgetter(\"result\"), reverse=True)\n",
    "    with open(\"resultados/decisionTree/decisionTree\" + str(i+1) + \".txt\", \"w\") as file:\n",
    "        pprint.pprint(r, stream=file, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDecisionTree = printResultadosDecisionTree(criterion=\"gini\", splitter=\"best\", max_depth = None, tipoKfold=\"KFold\", scoring=\"accuracy\", n_splits=10, x_train=x_train, y_train=y_train)\n",
    "dot_data = tree.export_graphviz(modelDecisionTree, out_file=None, \n",
    "                                feature_names=x_train.columns,  \n",
    "                                # class_names=iris.target_names,\n",
    "                                filled=True)\n",
    "\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format=\"png\")\n",
    "display(graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvores aleatórias (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResultadosRandomForest(n_estimators, criterion, max_depth, tipoKfold, scoring, n_splits, x_train, y_train):\n",
    "    print(\">> Modelo : Random Forest \" + \"; Estimators : \" + str(n_estimators) + \" ; Criterion : \" + criterion + \" ; Max_depth : \" + str(max_depth) + \" ; KFold : \" + tipoKfold + \" ; Scoring : \" + scoring + \" ; Splits : \" + str(n_splits))\n",
    "\n",
    "    modelRandomForest = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth)\n",
    "    modelRandomForest.fit(x_train, y_train)\n",
    "    y_pred = modelRandomForest.predict(x_test)\n",
    "\n",
    "    if (tipoKfold == \"KFold\"):\n",
    "        cv = KFold(n_splits=n_splits, shuffle=True)\n",
    "    elif (tipoKfold == \"StratifiedKFold\"):\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    vec = []\n",
    "    for i in range (10):\n",
    "        scoresModel = cross_val_score(modelRandomForest, x_train, y_train, cv=cv, scoring=scoring)\n",
    "        vec.append(scoresModel)\n",
    "        # print(scoresModel)\n",
    "    \n",
    "    result = np.mean(vec, axis=0)\n",
    "    \n",
    "    return np.mean(result), np.std(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForestAllCombinations():\n",
    "    estimators = [100, 150]\n",
    "    criterions = ['gini', 'log_loss']\n",
    "    max_depths = [10, 15]\n",
    "    kfolds = ['StratifiedKFold']\n",
    "    splits = [10, 20]\n",
    "\n",
    "    randomForestResults = []\n",
    "    for estimator in estimators:\n",
    "        for criterion in criterions:\n",
    "            for max_depth in max_depths:\n",
    "                for kfold in kfolds:\n",
    "                    for split in splits:\n",
    "                        randomForestResults.append({\"estimator\": estimator, \"criterion\": criterion, \"kfold\": kfold, \"max_depth\": max_depth, \"splits\" : split, \"result\": printResultadosRandomForest(estimator, criterion, max_depth, kfold, 'f1', split, x_train, y_train)})\n",
    "\n",
    "    return randomForestResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    r = randomForestAllCombinations()\n",
    "    r.sort(key=operator.itemgetter(\"result\"), reverse=True)\n",
    "    with open(\"resultados/randomForest/randomForest\" + str(i+1) + \".txt\", \"w\") as file:\n",
    "        pprint.pprint(r, stream=file, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRandomForest = printResultadosRandomForest(100, 'gini', None, 'KFold', 'accuracy', 10, x_train, y_train)\n",
    "for i in range(3):\n",
    "    tree = modelRandomForest.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=x_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=20, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes de Subconjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média e desvio padrão do modelo com scoring=\"f1\"\n",
      "(0.7174583194583194, 0.007528431223232198)\n",
      "\n",
      "Média e desvio padrão do modelo com scoring=\"f1_weighted\"\n",
      "(0.8293554811626391, 0.004388782700671246)\n",
      "\n",
      "Respostas do modelo para conjunto de teste:\n",
      "    Resultado\n",
      "0           1\n",
      "1           0\n",
      "2           0\n",
      "3           1\n",
      "4           0\n",
      "..        ...\n",
      "95          0\n",
      "96          1\n",
      "97          0\n",
      "98          0\n",
      "99          0\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Testes do modelo que gerou os resultados enviados para submissão\n",
    "\n",
    "modelRandomForest = RandomForestClassifier(n_estimators=150, criterion=\"log_loss\", max_depth=15)\n",
    "\n",
    "# Atributos considerados relevantes: I1, I5, I7, I8, I9, I10, M1, M2, M3, M4, M5, M8, M10\n",
    "\n",
    "nx_train = x_train.drop(\"I2\", axis=1)\n",
    "nx_train = nx_train.drop(\"I3\", axis=1)\n",
    "nx_train = nx_train.drop(\"I4\", axis=1)\n",
    "nx_train = nx_train.drop(\"I6\", axis=1)\n",
    "nx_train = nx_train.drop(\"M6\", axis=1)\n",
    "nx_train = nx_train.drop(\"M7\", axis=1)\n",
    "nx_train = nx_train.drop(\"M9\", axis=1)\n",
    "\n",
    "modelRandomForest.fit(nx_train, y_train)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=20, shuffle=True)\n",
    "\n",
    "vec = []\n",
    "for i in range (10):\n",
    "    scoresModel = cross_val_score(modelRandomForest, nx_train, y_train, cv=cv, scoring=\"f1\")\n",
    "    vec.append(scoresModel)\n",
    "    # print(scoresModel)\n",
    "\n",
    "result = np.mean(vec, axis=1)\n",
    "\n",
    "print(\"Média e desvio padrão do modelo com scoring=\\\"f1\\\"\")\n",
    "print((np.mean(result), np.std(result)))\n",
    "print()\n",
    "\n",
    "vec = []\n",
    "for i in range (10):\n",
    "    scoresModel = cross_val_score(modelRandomForest, nx_train, y_train, cv=cv, scoring=\"f1_weighted\")\n",
    "    vec.append(scoresModel)\n",
    "    # print(scoresModel)\n",
    "\n",
    "result = np.mean(vec, axis=1)\n",
    "\n",
    "print(\"Média e desvio padrão do modelo com scoring=\\\"f1_weighted\\\"\")\n",
    "print((np.mean(result), np.std(result)))\n",
    "print()\n",
    "\n",
    "nx_test = x_test.drop(\"I2\", axis=1)\n",
    "nx_test = nx_test.drop(\"I3\", axis=1)\n",
    "nx_test = nx_test.drop(\"I4\", axis=1)\n",
    "nx_test = nx_test.drop(\"I6\", axis=1)\n",
    "nx_test = nx_test.drop(\"M6\", axis=1)\n",
    "nx_test = nx_test.drop(\"M7\", axis=1)\n",
    "nx_test = nx_test.drop(\"M9\", axis=1)\n",
    "\n",
    "y_pred = modelRandomForest.predict(nx_test)\n",
    "\n",
    "df = pd.DataFrame(y_pred, columns=[\"Resultado\"])\n",
    "\n",
    "df.to_csv(\"submissao.csv\", sep=\";\")\n",
    "print(\"Respostas do modelo para conjunto de teste:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui são apenas outros testes realizados\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=150, criterion='log_loss', max_depth=15)\n",
    "# nx_train = x_train.drop(\"M8\", axis=1)\n",
    "# nx_train = x_train.drop(\"M6\", axis=1)\n",
    "# nx_train = x_train.drop(\"I6\", axis=1)\n",
    "# nx_train = x_train.drop(\"I3\", axis=1)\n",
    "nx_train = x_train.drop(\"I1\", axis=1)\n",
    "nx_train = nx_train.drop(\"I4\", axis=1)\n",
    "nx_train = nx_train.drop(\"I6\", axis=1)\n",
    "nx_train = nx_train.drop(\"I7\", axis=1)\n",
    "nx_train = nx_train.drop(\"I10\", axis=1)\n",
    "nx_train = nx_train.drop(\"M4\", axis=1)\n",
    "nx_train = nx_train.drop(\"M5\", axis=1)\n",
    "nx_train = nx_train.drop(\"M6\", axis=1)\n",
    "nx_train = nx_train.drop(\"M8\", axis=1)\n",
    "model.fit(nx_train, y_train)\n",
    "print(model.feature_importances_)\n",
    "\n",
    "# nx_test = x_test.drop(\"M8\", axis=1)\n",
    "# nx_test = x_test.drop(\"M6\", axis=1)\n",
    "# nx_test = x_test.drop(\"I6\", axis=1)\n",
    "# nx_test = x_test.drop(\"I3\", axis=1)\n",
    "nx_test = x_test.drop(\"I1\", axis=1)\n",
    "nx_test = nx_test.drop(\"I4\", axis=1)\n",
    "nx_test = nx_test.drop(\"I6\", axis=1)\n",
    "nx_test = nx_test.drop(\"I7\", axis=1)\n",
    "nx_test = nx_test.drop(\"I10\", axis=1)\n",
    "nx_test = nx_test.drop(\"M4\", axis=1)\n",
    "nx_test = nx_test.drop(\"M5\", axis=1)\n",
    "nx_test = nx_test.drop(\"M6\", axis=1)\n",
    "nx_test = nx_test.drop(\"M8\", axis=1)\n",
    "y_pred = model.predict(nx_test)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=20, shuffle=True)\n",
    "scoresModel = cross_val_score(model, x_train, y_train, cv=cv, scoring='f1')\n",
    "\n",
    "print(np.mean(scoresModel), np.std(scoresModel))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjuntoTreinamento.info()\n",
    "conjuntoTreinamento.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(conjuntoTreinamento, hue=\"Resultado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "161e30f16301fb1921d0fc4b5a5ba5793a44f167b6a6d3ecec21fb0270796fcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
